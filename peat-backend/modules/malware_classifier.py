"""
Malware Classifier and Risk Scoring Engine
Combines all analysis modules to classify and score malware
"""

import os
from datetime import datetime
from .universal_binary_parser import UniversalBinaryParser
from .entropy_analyzer import EntropyAnalyzer
from .ioc_extractor import IoCExtractor
from .signature_scanner import SignatureScanner

class MalwareClassifier:

    def __init__(self, yara_rules_dir='yara_rules'):
        self.scanner = SignatureScanner(yara_rules_dir)

    def analyze(self, file_path):
        """Perform comprehensive malware analysis"""
        try:
            # Initialize results
            results = {
                'success': True,
                'analyzed_at': datetime.utcnow().isoformat() + 'Z',
                'file_path': file_path,
                'file_name': os.path.basename(file_path),
                'file_size': os.path.getsize(file_path)
            }

            # 1. Binary Parsing (supports ELF, Mach-O, PE)
            print("Parsing binary...")
            binary_parser = UniversalBinaryParser(file_path)
            elf_data = binary_parser.parse()
            results['elf'] = elf_data
            print(f"  Format: {elf_data['file_info']['format']}")

            # 2. Entropy Analysis
            print("Analyzing entropy...")
            entropy = EntropyAnalyzer.analyze_file(file_path)
            section_entropy = EntropyAnalyzer.analyze_sections(file_path, elf_data['sections'])
            results['entropy'] = {
                **entropy,
                'sections': section_entropy
            }

            # 3. IoC Extraction
            print("Extracting IoCs...")
            iocs = IoCExtractor.extract_from_strings(elf_data['strings'])
            ioc_classification = IoCExtractor.classify_severity(iocs)
            results['iocs'] = {
                **iocs,
                'classification': ioc_classification
            }

            # 4. YARA Signature Scanning
            print("Scanning with YARA signatures...")
            yara_results = self.scanner.scan(file_path)
            malware_family = self.scanner.get_malware_family(yara_results.get('matches', []))
            results['signatures'] = {
                **yara_results,
                'family': malware_family
            }

            # 5. Classification & Risk Scoring
            print("Calculating risk score...")
            classification = self._classify_malware(results)
            results['classification'] = classification

            # 6. Generate Threats
            results['threats'] = self._generate_threats(results)

            # 7. Generate Timeline
            results['timeline'] = self._generate_timeline(results)

            # 8. Generate Network Activity
            results['network_activity'] = self._generate_network_activity(iocs)

            # 9. Generate Recommendations
            results['recommendations'] = self._generate_recommendations(classification)

            # 10. Device Info (mock for now, could be enhanced)
            results['device_info'] = {
                'type': 'IoT Device Binary',
                'architecture': elf_data['header']['machine'],
                'class': elf_data['header']['class'],
                'format': 'ELF'
            }

            print(f"Analysis complete. Risk: {classification['risk_score']}/100, Family: {classification['family']}")

            return results

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'file_path': file_path
            }

    def _classify_malware(self, results):
        """Classify malware and calculate risk score"""
        risk_score = 0
        confidence = 0
        family = 'Unknown'
        category = 'Suspicious Binary'
        severity = 'LOW'

        # YARA signature matches (highest priority)
        if results['signatures'].get('matched'):
            risk_score += 40
            confidence += 30
            if results['signatures']['family']:
                family = results['signatures']['family']['family']
                severity = results['signatures']['family']['severity']
                category = family
                risk_score += 20
                confidence += 30

        # IoC severity
        ioc_severity = results['iocs']['classification']['severity']
        if ioc_severity == 'CRITICAL':
            risk_score += 25
            confidence += 20
        elif ioc_severity == 'HIGH':
            risk_score += 15
            confidence += 15
        elif ioc_severity == 'MEDIUM':
            risk_score += 8
            confidence += 10

        # Entropy analysis (packing/encryption)
        if results['entropy']['is_packed']:
            risk_score += 10
            confidence += 10
            if category == 'Suspicious Binary':
                category = 'Packed/Encrypted Binary'

        # Suspicious strings count
        susp_count = len(results['iocs']['suspicious_strings'])
        if susp_count > 10:
            risk_score += 15
            confidence += 15
        elif susp_count > 5:
            risk_score += 8
            confidence += 8

        # Network indicators
        if len(results['iocs']['ips']) > 5 or len(results['iocs']['urls']) > 3:
            risk_score += 10
            confidence += 10

        # Cap scores
        risk_score = min(risk_score, 100)
        confidence = min(confidence, 100)

        # Determine final severity
        if risk_score >= 70:
            severity = 'CRITICAL'
        elif risk_score >= 50:
            severity = 'HIGH'
        elif risk_score >= 30:
            severity = 'MEDIUM'
        else:
            severity = 'LOW'

        return {
            'family': family,
            'category': category,
            'severity': severity,
            'risk_score': risk_score,
            'confidence': confidence,
            'is_malware': risk_score >= 40,
            'analysis_method': 'REAL'
        }

    def _generate_threats(self, results):
        """Generate threat list from analysis results"""
        threats = []
        threat_id = 1

        # YARA matches -> threats
        for match in results['signatures'].get('matches', []):
            threats.append({
                'id': f'THR-{str(threat_id).zfill(3)}',
                'severity': match.get('meta', {}).get('severity', 'MEDIUM'),
                'category': 'Malware Signature',
                'name': f"Detected: {match['rule']}",
                'description': match.get('meta', {}).get('description', f"YARA rule {match['rule']} matched"),
                'impact': self._get_impact_for_family(match.get('meta', {}).get('family', '')),
                'location': f"Rule: {match['rule']}, Namespace: {match.get('namespace', 'default')}",
                'confidence': 92,
                'evidence': {
                    'rule': match['rule'],
                    'matched_strings': len(match.get('strings', []))
                }
            })
            threat_id += 1

        # Suspicious strings -> threats
        for susp_str in results['iocs']['suspicious_strings'][:5]:
            threats.append({
                'id': f'THR-{str(threat_id).zfill(3)}',
                'severity': 'HIGH',
                'category': 'Suspicious String',
                'name': f"Suspicious keyword found",
                'description': f"Binary contains suspicious string: '{susp_str[:50]}'",
                'impact': 'May indicate malicious functionality or behavior',
                'location': f"String: {susp_str[:80]}",
                'confidence': 75,
                'evidence': {'string': susp_str}
            })
            threat_id += 1

        # High entropy -> threat
        if results['entropy']['is_packed']:
            threats.append({
                'id': f'THR-{str(threat_id).zfill(3)}',
                'severity': 'MEDIUM',
                'category': 'Obfuscation',
                'name': 'Packed/Encrypted Binary',
                'description': f"High entropy ({results['entropy']['overall']}) indicates packing or encryption",
                'impact': 'Code obfuscation commonly used by malware to evade detection',
                'location': f"Overall entropy: {results['entropy']['overall']}, {results['entropy']['high_entropy_chunks']} high-entropy chunks",
                'confidence': 80,
                'evidence': {'entropy': results['entropy']['overall']}
            })
            threat_id += 1

        # Network IoCs -> threats
        if len(results['iocs']['ips']) > 0:
            threats.append({
                'id': f'THR-{str(threat_id).zfill(3)}',
                'severity': 'HIGH',
                'category': 'Network',
                'name': 'External IP Addresses Embedded',
                'description': f"Binary contains {len(results['iocs']['ips'])} hardcoded IP addresses",
                'impact': 'May indicate command-and-control communication or data exfiltration endpoints',
                'location': f"IPs: {', '.join(results['iocs']['ips'][:5])}",
                'confidence': 85,
                'evidence': {'ips': results['iocs']['ips']}
            })
            threat_id += 1

        return threats

    def _generate_timeline(self, results):
        """Generate attack timeline"""
        timeline = []
        now = datetime.utcnow()

        timeline.append({
            'timestamp': now.isoformat() + 'Z',
            'category': 'Analysis',
            'event': 'Binary analysis initiated',
            'severity': 'info',
            'details': f"Analyzing {results['file_name']} ({results['file_size']} bytes)"
        })

        if results['signatures'].get('matched'):
            timeline.append({
                'timestamp': now.isoformat() + 'Z',
                'category': 'Detection',
                'event': f"Malware signature matched: {results['signatures']['matches'][0]['rule']}",
                'severity': 'critical',
                'details': f"Family: {results['classification']['family']}"
            })

        if len(results['iocs']['suspicious_strings']) > 0:
            timeline.append({
                'timestamp': now.isoformat() + 'Z',
                'category': 'Forensics',
                'event': f"Suspicious indicators found",
                'severity': 'warning',
                'details': f"{len(results['iocs']['suspicious_strings'])} suspicious strings, {len(results['iocs']['ips'])} IPs extracted"
            })

        timeline.append({
            'timestamp': now.isoformat() + 'Z',
            'category': 'Analysis',
            'event': 'Analysis completed',
            'severity': 'info',
            'details': f"Risk score: {results['classification']['risk_score']}/100"
        })

        return timeline

    def _generate_network_activity(self, iocs):
        """Format network activity from IoCs"""
        network = []

        for ip in iocs['ips'][:10]:
            network.append({
                'ip': ip,
                'port': 'Multiple' if len(iocs['ports']) > 1 else str(iocs['ports'][0]) if iocs['ports'] else 'Unknown',
                'protocol': 'TCP',
                'reputation': 'Suspicious - Embedded in malware',
                'country': 'Unknown'
            })

        return network

    def _generate_recommendations(self, classification):
        """Generate remediation recommendations"""
        recommendations = []

        if classification['severity'] == 'CRITICAL':
            recommendations.append({
                'priority': 'IMMEDIATE',
                'action': 'Isolate affected device immediately',
                'rationale': f"Critical threat detected: {classification['family']}"
            })

        if classification['risk_score'] >= 50:
            recommendations.append({
                'priority': 'IMMEDIATE',
                'action': 'Do not execute this binary',
                'rationale': f"High risk score ({classification['risk_score']}/100) indicates malicious intent"
            })

        if classification['is_malware']:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'Submit to malware repository for analysis',
                'rationale': 'Confirmed malware sample should be catalogued for threat intelligence'
            })
            recommendations.append({
                'priority': 'HIGH',
                'action': 'Scan all devices on network',
                'rationale': 'Check for lateral movement or additional compromised devices'
            })

        recommendations.append({
            'priority': 'MEDIUM',
            'action': 'Update IoT device firmware',
            'rationale': 'Ensure all security patches are applied'
        })

        recommendations.append({
            'priority': 'MEDIUM',
            'action': 'Review firewall rules and network segmentation',
            'rationale': 'Prevent unauthorized external communications'
        })

        return recommendations

    def _get_impact_for_family(self, family):
        """Get impact description for malware family"""
        impacts = {
            'Mirai': 'Device becomes part of DDoS botnet. Can be used for large-scale attacks, credential theft, and spreading to other devices.',
            'Gafgyt': 'DDoS botnet malware. Compromised device used for network attacks and may scan for other vulnerable devices.',
            'Qbot': 'Banking trojan and botnet malware. Can steal credentials, exfiltrate data, and download additional payloads.',
            'Cryptominer': 'Unauthorized cryptocurrency mining. Degrades performance, increases power consumption, potential hardware damage.',
            'Backdoor': 'Provides unauthorized remote access. Attacker can execute commands, steal data, install additional malware.',
            'Reverse_Shell': 'Establishes persistent remote access. Complete system control for attacker.',
            'Rootkit': 'Deep system compromise with stealth capabilities. Can hide processes, files, and network connections.'
        }
        return impacts.get(family, 'Malicious activity detected. Full impact assessment recommended.')
